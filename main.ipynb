{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re  # regex\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing iniail values\n",
    "df = pd.read_csv(\"imdb_master.csv\", sep=\",\", encoding=\"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test' 'train']\n",
      "['neg' 'pos' 'unsup']\n"
     ]
    }
   ],
   "source": [
    "# checking initail values\n",
    "print(df['type'].unique())\n",
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>train</td>\n",
       "      <td>Delightfully awful! Made by David Giancola, a ...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>train</td>\n",
       "      <td>Watching Time Chasers, it obvious that it was ...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>train</td>\n",
       "      <td>At the beginning we can see members of Troma t...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>train</td>\n",
       "      <td>The movie was incredible, ever since I saw it ...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>train</td>\n",
       "      <td>TCM came through by acquiring this wonderful, ...</td>\n",
       "      <td>unsup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        type                                             review  label\n",
       "0       test  Once again Mr. Costner has dragged out a movie...    neg\n",
       "1       test  This is an example of why the majority of acti...    neg\n",
       "2       test  First of all I hate those moronic rappers, who...    neg\n",
       "3       test  Not even the Beatles could write songs everyon...    neg\n",
       "4       test  Brass pictures (movies is not a fitting word f...    neg\n",
       "...      ...                                                ...    ...\n",
       "99995  train  Delightfully awful! Made by David Giancola, a ...  unsup\n",
       "99996  train  Watching Time Chasers, it obvious that it was ...  unsup\n",
       "99997  train  At the beginning we can see members of Troma t...  unsup\n",
       "99998  train  The movie was incredible, ever since I saw it ...  unsup\n",
       "99999  train  TCM came through by acquiring this wonderful, ...  unsup\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop(df.columns[3], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "CLEANR = re.compile(\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n",
    "nltk.download(\"punkt\")\n",
    "ps = PorterStemmer()\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def remove_stop_words(sentence):\n",
    "    # Split the sentence into individual words\n",
    "    words = sentence.split()\n",
    "    # Use a list comprehension to remove stop words\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    # Join the filtered words back into a sentence\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "def remove_html_tags(sentence):\n",
    "    return re.sub(CLEANR, \"\", sentence)\n",
    "\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "def remove_none_words(sentence):\n",
    "    sentence = re.sub(r\"[0-9]+\", \"\", sentence)\n",
    "    return re.sub(r\"\\W+\", \" \", sentence)\n",
    "\n",
    "\n",
    "def apply_stemmer(sentence):\n",
    "    return ps.stem(sentence)\n",
    "\n",
    "\n",
    "def apply_lemmatization(sentence):\n",
    "    return wnl.lemmatize(sentence)\n",
    "\n",
    "\n",
    "def get_words_tokens(sentence):\n",
    "    return word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>review_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>once mr costner dragged movie far longer neces...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[once, mr, costner, dragged, movie, far, longe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>this example majority action films generic bor...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[this, example, majority, action, films, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>first i hate moronic rappers couldnt act gun p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[first, i, hate, moronic, rappers, couldnt, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>not even beatles could write songs everyone li...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[not, even, beatles, could, write, songs, ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>brass pictures movies fitting word really some...</td>\n",
       "      <td>neg</td>\n",
       "      <td>[brass, pictures, movies, fitting, word, reall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             review label  \\\n",
       "0  test  once mr costner dragged movie far longer neces...   neg   \n",
       "1  test  this example majority action films generic bor...   neg   \n",
       "2  test  first i hate moronic rappers couldnt act gun p...   neg   \n",
       "3  test  not even beatles could write songs everyone li...   neg   \n",
       "4  test  brass pictures movies fitting word really some...   neg   \n",
       "\n",
       "                                        review_token  \n",
       "0  [once, mr, costner, dragged, movie, far, longe...  \n",
       "1  [this, example, majority, action, films, gener...  \n",
       "2  [first, i, hate, moronic, rappers, couldnt, ac...  \n",
       "3  [not, even, beatles, could, write, songs, ever...  \n",
       "4  [brass, pictures, movies, fitting, word, reall...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows data clean\n",
    "review_token = []\n",
    "for index, row in df.iterrows():\n",
    "    row[\"review\"] = remove_html_tags(row[\"review\"])\n",
    "    row[\"review\"] = remove_punctuation(row[\"review\"])\n",
    "    row[\"review\"] = remove_stop_words(row[\"review\"])\n",
    "    row[\"review\"] = remove_none_words(row[\"review\"])\n",
    "    row[\"review\"] = row[\"review\"].lower()\n",
    "    row[\"review\"] = apply_stemmer(row[\"review\"])\n",
    "    row[\"review\"] = apply_lemmatization(row[\"review\"])\n",
    "    review_token.append(get_words_tokens(row[\"review\"]))\n",
    "\n",
    "df[\"review_token\"] = review_token\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>absence</th>\n",
       "      <th>absurd</th>\n",
       "      <th>accomplices</th>\n",
       "      <th>across</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>actually</th>\n",
       "      <th>...</th>\n",
       "      <th>worker</th>\n",
       "      <th>worried</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrought</th>\n",
       "      <th>youre</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zsigmond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>...</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.218876</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>2.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ability   absence    absurd  accomplices    across    acting    action  \\\n",
       "0  0.000000  0.000000  5.218876     0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000     2.609438  0.000000  2.609438  2.609438   \n",
       "2  0.000000  0.000000  0.000000     0.000000  2.609438  0.000000  0.000000   \n",
       "3  0.000000  2.609438  0.000000     0.000000  0.000000  0.000000  0.000000   \n",
       "4  2.609438  0.000000  0.000000     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     actors   actress  actually  ...    worker   worried     worse     worst  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  2.609438  ...  2.609438  2.609438  2.609438  0.000000   \n",
       "2  5.218876  2.609438  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  2.609438   \n",
       "\n",
       "      would       wow   wrought     youre  youthful  zsigmond  \n",
       "0  1.916291  0.000000  0.000000  0.000000  0.000000  2.609438  \n",
       "1  1.916291  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  2.609438  0.000000  \n",
       "3  0.000000  2.609438  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  2.609438  2.609438  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 638 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(norm=None, smooth_idf=False)\n",
    "train_data = df.query('type == \"train\"').head()[\"review\"]\n",
    "x_tfidf = tfidf.fit_transform(train_data)\n",
    "\n",
    "vecor = pd.DataFrame(x_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "vecor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'story man unnatural feelings pig starts opening scene terrific example absurd comedy a formal orchestra audience turned insane violent mob crazy chantings singers unfortunately stays absurd whole time general narrative eventually making putting even era turned the cryptic dialogue would make shakespeare seem easy third grader on technical level better might think good cinematography future great vilmos zsigmond future stars sally kirkland frederic forrest seen briefli'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/nlp_Assignment2/main.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-dollop-4ggq6x5pg74fq4pp/workspaces/nlp_Assignment2/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m y_test \u001b[39m=\u001b[39m y_test\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-dollop-4ggq6x5pg74fq4pp/workspaces/nlp_Assignment2/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m clf \u001b[39m=\u001b[39m MultinomialNB(force_alpha\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bshiny-dollop-4ggq6x5pg74fq4pp/workspaces/nlp_Assignment2/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(x_train, y_train\u001b[39m.\u001b[39;49mravel())\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-dollop-4ggq6x5pg74fq4pp/workspaces/nlp_Assignment2/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m predictions \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bshiny-dollop-4ggq6x5pg74fq4pp/workspaces/nlp_Assignment2/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    726\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \n\u001b[1;32m    728\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[1;32m    746\u001b[0m     _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    748\u001b[0m     labelbin \u001b[39m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/naive_bayes.py:578\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X_y\u001b[39m(\u001b[39mself\u001b[39m, X, y, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    577\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49mreset)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1147\u001b[0m     X,\n\u001b[1;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1160\u001b[0m )\n\u001b[1;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    954\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'story man unnatural feelings pig starts opening scene terrific example absurd comedy a formal orchestra audience turned insane violent mob crazy chantings singers unfortunately stays absurd whole time general narrative eventually making putting even era turned the cryptic dialogue would make shakespeare seem easy third grader on technical level better might think good cinematography future great vilmos zsigmond future stars sally kirkland frederic forrest seen briefli'"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()  # chnage the none intger cloumns to intger cloumns\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "\n",
    "df_train = df.query(\"type == 'train'\")\n",
    "df_test = df.query(\"type == 'test'\")\n",
    "\n",
    "x_train = df_train[\"review\"]\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "x_test = df_test[\"review\"]\n",
    "y_test = df_test[\"label\"]\n",
    "\n",
    "y_test = y_test.values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "clf = MultinomialNB(force_alpha=True)\n",
    "clf.fit(x_train, y_train.ravel())\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(predictions)\n",
    "accuracy_result = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(accuracy_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
